{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy.lang.en import English\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from math import sqrt\n",
    "from nltk.corpus import wordnet\n",
    "import json\n",
    "#from py_thesaurus import Thesaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Interchange File.json') as file:\n",
    "        interchange = json.load(file)\n",
    "        \n",
    "with open('Source File.json') as src:\n",
    "        source = json.load(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_Msg = \"Address is wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Dict = pd.read_csv(\"Data Dictionary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Primary Object</th>\n",
       "      <th>Field Name</th>\n",
       "      <th>Field description</th>\n",
       "      <th>Canonical Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Customer</td>\n",
       "      <td>FirstName</td>\n",
       "      <td>First Name of the Applicant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LastName</td>\n",
       "      <td>Last Name of the Applicant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AddressLine1</td>\n",
       "      <td>Address Line1 of the Applicant</td>\n",
       "      <td>Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AddressLine2</td>\n",
       "      <td>Address Line2 of the Applicant</td>\n",
       "      <td>Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zipcode</td>\n",
       "      <td>Social Security Number of the Applicant</td>\n",
       "      <td>pincode, area code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SSN</td>\n",
       "      <td>Social Security Number of the Applicant</td>\n",
       "      <td>Social security number, unique id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Claim Details</td>\n",
       "      <td>RevenueCode</td>\n",
       "      <td>Revenue Code for the Claim</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ClaimAmount</td>\n",
       "      <td>Total Claim Amount of the Claim</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Primary Object   Field Name                         Field description  \\\n",
       "0       Customer    FirstName              First Name of the Applicant    \n",
       "1            NaN     LastName               Last Name of the Applicant    \n",
       "2            NaN  AddressLine1           Address Line1 of the Applicant   \n",
       "3            NaN  AddressLine2           Address Line2 of the Applicant   \n",
       "4            NaN      Zipcode   Social Security Number of the Applicant   \n",
       "5            NaN           SSN  Social Security Number of the Applicant   \n",
       "6  Claim Details   RevenueCode               Revenue Code for the Claim   \n",
       "7            NaN  ClaimAmount           Total Claim Amount of the Claim   \n",
       "\n",
       "                    Canonical Values  \n",
       "0                                NaN  \n",
       "1                                NaN  \n",
       "2                            Address  \n",
       "3                            Address  \n",
       "4                 pincode, area code  \n",
       "5  Social security number, unique id  \n",
       "6                                NaN  \n",
       "7                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the list of stopwords in spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First ten stop words: ['toward', 'three', 'be', 'my', 'below', 'formerly', 'must', 'own', 'himself', 'whole']\n"
     ]
    }
   ],
   "source": [
    "spacy_Stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "print('Number of stop words: %d' % len(spacy_Stopwords))\n",
    "print('First ten stop words: %s' % list(spacy_Stopwords)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"nlp\" Object is used to create documents with linguistic annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address is wrong"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_msg = nlp(error_Msg)\n",
    "my_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating list of tokens from the error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = []\n",
    "for token in my_msg:\n",
    "    token_list.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Address', 'is', 'wrong']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating list of tokens after removing stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_errorMsg = []\n",
    "for word in token_list:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    if lexeme.is_stop == False:\n",
    "        filtered_errorMsg.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Address', 'is', 'wrong']\n"
     ]
    }
   ],
   "source": [
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Address', 'wrong']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_errorMsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address wrong\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(filtered_errorMsg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address wrong "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_Msg = []\n",
    "new_myMsg = \"\"\n",
    "for word in filtered_errorMsg:\n",
    "    new_myMsg += word + \" \"\n",
    "new_myMsg = nlp(new_myMsg)\n",
    "new_myMsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lem_word in new_myMsg:\n",
    "    filtered_Msg.append(lem_word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Address', 'wrong']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_Msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address wrong\n"
     ]
    }
   ],
   "source": [
    "print( \" \".join(filtered_Msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary Object', 'Field Name ', 'Field description',\n",
       "       'Canonical Values'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Dict.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing white space at the end of the column name \n",
    "data_Dict.columns = data_Dict.columns.str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Primary Object', 'Field Name', 'Field description',\n",
       "       'Canonical Values'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_Dict.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_Name= data_Dict['Field Name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FirstName ',\n",
       " 'LastName ',\n",
       " 'AddressLine1',\n",
       " 'AddressLine2',\n",
       " 'Zipcode ',\n",
       " 'SSN',\n",
       " 'RevenueCode',\n",
       " 'ClaimAmount ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a matching word AddressLine1 with original word: Address\n",
      "The similar word from Field names is:  AddressLine1\n",
      "The error to be replaced in the interchange file is :   302, Street Avenue\n",
      "The error to be replaced with from the source file is :   302, Street Avenue\n",
      "Found a matching word AddressLine2 with original word: Address\n",
      "The similar word from Field names is:  AddressLine2\n",
      "The error to be replaced in the interchange file is :   India\n",
      "The error to be replaced with from the source file is :   japan\n"
     ]
    }
   ],
   "source": [
    "def word2vec(word):\n",
    "    \n",
    "    # count the characters in word\n",
    "    cw = Counter(word)\n",
    "    \n",
    "    # set of the different characters\n",
    "    sw = set(cw)\n",
    "    \n",
    "    # precomputes the \"length\" of the word vector\n",
    "    lw = sqrt(sum(c*c for c in cw.values()))\n",
    "    \n",
    "    # return a tuple\n",
    "    return cw, sw, lw\n",
    "\n",
    "def cosdis(v1, v2):\n",
    "    # which characters are common to the two words\n",
    "    common = v1[1].intersection(v2[1])\n",
    "   \n",
    "    # by definition of cosine distance\n",
    "    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]\n",
    "\n",
    "threshold = 0.80    \n",
    "for key in filtered_Msg:\n",
    "    for word in field_Name:\n",
    "        try:\n",
    "\n",
    "            res = cosdis(word2vec(word), word2vec(key))\n",
    "            if res > threshold:\n",
    "                print(\"Found a matching word {} with original word: {}\".format(word, key))\n",
    "                new_word = word\n",
    "                print(\"The similar word from Field names is: \", new_word)\n",
    "                # Interchange file\n",
    "                class AppConfiguration():\n",
    "                    def __init__(self, data=None):\n",
    "                        if data is None:\n",
    "                            with open(\"Interchange File.json\") as fh:\n",
    "                                data = json.loads(fh.read())\n",
    "                        else:\n",
    "                            data = dict(data)\n",
    "                        for key, val in data.items():\n",
    "                            setattr(self, key, self.compute_attr_value(val))\n",
    "\n",
    "                    def compute_attr_value(self, value):\n",
    "                        if type(value) is list:\n",
    "                            return [self.compute_attr_value(x) for x in value]\n",
    "                        elif type(value) is dict:\n",
    "                            return AppConfiguration(value)\n",
    "                        else:\n",
    "                            return value\n",
    "                instance = AppConfiguration()\n",
    "                custInstance=instance.Customer\n",
    "                interchange_attribute=getattr(custInstance,new_word)\n",
    "#               print(a)\n",
    "#               inter_att = instance.Customer.AddressLine2\n",
    "                print(\"The error to be replaced in the interchange file is :  \",interchange_attribute)\n",
    "                \n",
    "                class AppConfiguration():\n",
    "                    def __init__(self, data=None):\n",
    "                        if data is None:\n",
    "                            with open(\"Source File.json\") as fh:\n",
    "                                data = json.loads(fh.read())\n",
    "                        else:\n",
    "                            data = dict(data)\n",
    "                        for key, val in data.items():\n",
    "                            setattr(self, key, self.compute_attr_value(val))\n",
    "\n",
    "                    def compute_attr_value(self, value):\n",
    "                        if type(value) is list:\n",
    "                            return [self.compute_attr_value(x) for x in value]\n",
    "                        elif type(value) is dict:\n",
    "                            return AppConfiguration(value)\n",
    "                        else:\n",
    "                            return value\n",
    "                instance = AppConfiguration()\n",
    "                custInstance=instance.Customer\n",
    "                source_attribute=getattr(custInstance,new_word)\n",
    "                print(\"The error to be replaced with from the source file is :  \",source_attribute)\n",
    "                interchange['Customer'][new_word] = source_attribute\n",
    "                with open('Interchange File.json', 'w') as fp:\n",
    "                    json.dump(interchange, fp,  indent=4)\n",
    "                \n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "# You can get the name by accessing the _name_ attribute of the class; \n",
    "# and if you have an object, you can get the class by accessing the _class_ attribute of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding the synonym of the error word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synonyms = []\n",
    "# for syn in wordnet.synsets(new_word):\n",
    "#     for lm in syn.lemmas():\n",
    "#              synonyms.append(lm.name())#adding into synonyms\n",
    "# syn_List = list(set(synonyms))\n",
    "# print (syn_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Above the function\n",
      "Found a matching word Address Line1 with original word: address\n",
      "Found a matching word Address Line2 with original word: address\n"
     ]
    }
   ],
   "source": [
    "print(\"Above the function\")\n",
    "def word2vec_syn(word):\n",
    "    \n",
    "    # count the characters in word\n",
    "    cw = Counter(word)\n",
    "    \n",
    "    # set of the different characters\n",
    "    sw = set(cw)\n",
    "    \n",
    "    # precomputes the \"length\" of the word vector\n",
    "    lw = sqrt(sum(c*c for c in cw.values()))\n",
    "#     print(\"Inside the function\")\n",
    "\n",
    "    # return a tuple\n",
    "    return cw, sw, lw\n",
    "\n",
    "def cosdis_syn(v1, v2):\n",
    "    # which characters are common to the two words\n",
    "    common = v1[1].intersection(v2[1])\n",
    "   \n",
    "    # by definition of cosine distance\n",
    "    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]\n",
    "\n",
    "threshold = 0.75    \n",
    "for key in syn_List:\n",
    "    for word in field_Name:\n",
    "        try:\n",
    "#           Cosine simililarity\n",
    "            res = cosdis_syn(word2vec_syn(word), word2vec_syn(key))\n",
    "#           print(\"The cosine similarity between : {} and : {} is: {}\".format(word, key, res*100))\n",
    "            if res > threshold:\n",
    "                print(\"Found a matching word {} with original word: {}\".format(word, key))\n",
    "#                 new_word_syn = key\n",
    "#                 print(\"The new word is \", new_word_syn)\n",
    "        except IndexError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjSyn = pd.read_csv(\"ErrorAdjectivesSynonym.txt\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>faulty incorrect not-working wrong false defec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Required</td>\n",
       "      <td>Excpected mandatory needed compulsory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Match</td>\n",
       "      <td>equal duplicate equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>incomplete misplaced removed short not-present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Adjectives                                           Synonyms\n",
       "0    Invalid  faulty incorrect not-working wrong false defec...\n",
       "1   Required             Excpected mandatory needed compulsory \n",
       "2      Match                         equal duplicate equivalent\n",
       "3    missing     incomplete misplaced removed short not-present"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjSyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
